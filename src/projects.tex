\section{Projects}

    % \resumeSubHeadingListStart
    %   \resumeProjectHeading
    %       {\textbf{Data Engineering Project} $|$ \emph{Airflow, Python, SQL, PySpark, Hive, CRON}}{In progress}
    %       \resumeItemListStart
    %         \resumeItem{}
    %       \resumeItemListEnd
    % \resumeSubHeadingListEnd
    
    \resumeSubHeadingListStart 
      \resumeProjectHeading
          {\href{https://github.com/benthecoder/gpt3-blog-title}{\faGithub\ \textbf{{GPT-3 Blog Title Optimizer}}} $|$ \emph{Python, Selenium, BeautifulSoup, OpenAI, Weights \& Biases, BigQuery, SQL, Streamlit}}{}
          \resumeItemListStart
            \resumeItem{Scraped 200k blog articles from medium.com with Selenium and BeautifulSoup and ingested data into BigQuery}
            \resumeItem{Utilized OpenAI's API to fine-tune GPT-3 to classify article titles and tracked experiments and dataset with W\&B}
            \resumeItem{Containerized the application with Docker and deployed the model as a web app using Streamlit for users}
          \resumeItemListEnd
    \resumeSubHeadingListEnd
    
    % \resumeSubHeadingListStart
    %   \resumeProjectHeading
    %       {\href{https://github.com/weichunnn/voice-out}{\faGithub\ \textbf{{Voice Out}}} $|$ \emph{TypeScript, React, NextJS, Google Cloud (Natural Language API \& Cloud Firestore)}}{}
    %       \resumeItemListStart
    %         \resumeItem{Led a team of 2 to build a web app that allows users to express their opinions on over 600 government agencies}
    %         \resumeItem{Used Google Cloud's Natural Language API to implement sentiment analysis and automatic categorization of posts}
    %         \resumeItem{Integrated Cloud Firestore into the application architecture to efficiently manage and retrieve user post data}
    %       \resumeItemListEnd
    % \resumeSubHeadingListEnd    
    
    \resumeSubHeadingListStart
      \resumeProjectHeading
          {\href{https://github.com/weichunnn/voice-out}{\faGithub\ \textbf{{Readabl}}} $|$ \emph{JavaScript, Python, Svelte, FastAPI, BeautifulSoup, NLTK, Google Cloud Platform (GCP), Docker}}{}
          \resumeItemListStart
            \resumeItem{Led a team of 4 to build a web app that offers readability metrics for google search results with the custom search API}
            \resumeItem{Implemented concurrent processing in the FastAPI backend to parse webpages in parallel and improve search speed}
            \resumeItem{Coded Svelte components to call the backend to receive search results and display results in an accessible format}
          \resumeItemListEnd
    \resumeSubHeadingListEnd
    
    \resumeSubHeadingListStart
      \resumeProjectHeading
          {\href{https://github.com/benthecoder/Energytics}{\faGithub\ \textbf{{Energytics}}} $|$ \emph{Python, Pandas, Scikit-learn, LightGBM, OpenWeatherMap API, Plotly, Seaborn, Streamlit}}{}
          \resumeItemListStart
            \resumeItem{Led a team of 6 to build a web app that visualizes energy production cost and building energy usage in the US}
            \resumeItem{Conducted EDA on 60 million records with 18 features to investigate trends, outliers, missing data, and anomalies}
            \resumeItem{Trained and deployed a LightGBM model to predict building energy usage with user location and building details}
            % \resumeItem{Performed feature preprocessing and generation to extract additional features from temporal and weather data}
          \resumeItemListEnd
    \resumeSubHeadingListEnd
    
    \resumeSubHeadingListStart
      \resumeProjectHeading
          {\href{https://github.com/benthecoder/linkedin-visualizer}{\faGithub\ \textbf{{LinkedIn Insights}}} $|$ \emph{Python, Numpy, Pandas, thefuzz, NLTK, Plotly, Pyvis, Networkx, Streamlit, wordcloud}}{}
          \resumeItemListStart
            \resumeItem{Developed a web app with 500+ users that allows them to gain insights into their LinkedIn connections}
            \resumeItem{Applied advanced data cleaning techniques, including fuzzy matching, to improve the accuracy of insights}
            \resumeItem{Visualized user connections and messages with interactive bar charts, time series plots, and network graphs}
          \resumeItemListEnd
    \resumeSubHeadingListEnd

    % \resumeSubHeadingListStart
    %   \resumeProjectHeading
    %       {\href{https://github.com/benthecoder/Ensurance}{\faGithub\ \textbf{{Ensurance}}} $|$ \emph{Python, Streamlit, Pandas, Google Cloud, Plotly}}{}
    %       \resumeItemListStart
    %         \resumeItem{Awarded Best Healthcare Hack Powered by Anthem for Georgia Techâ€™s 36 hour datathon - Hacklytics 2022}
    %         \resumeItem{Led a team of 4 to develop an interactive web app for evaluating health risks based on user demographics}
    %         \resumeItem{Aggregated data from multiple sources and performed data cleansing for analysis and visualization}
    %       \resumeItemListEnd
    % \resumeSubHeadingListEnd    

    
    % \resumeSubHeadingListStart
    %   \resumeProjectHeading
    %       {\href{https://github.com/benthecoder/TreeFinance}{\faGithub\ \textbf{{TreeFinance}}} $|$ \emph{Python, ReactJS, ChakraUI, Flask, Plotly, Plaid API, Twilio}}{}
    %       \resumeItemListStart
    %         \resumeItem{Led a team of 4 in the development of a web app that visualizes a user's climate impact using their financial data}
    %         \resumeItem{Coded the React app, implementing logic to retrieve data from the Flask backend using Plaid API integrations}
    %         \resumeItem{Implemented Twilio integration to send personalized chat messages highlighting the user's climate impact}
    %       \resumeItemListEnd
    % \resumeSubHeadingListEnd
    
    % \resumeSubHeadingListStart 
    %   \resumeProjectHeading
    %       {\href{https://github.com/benthecoder/next-word-predictor}{\faGithub\ \textbf{{Next Word Prediction}}} $|$ \emph{R, Shiny, Tidytext, Tidyverse, ggplot2, dplyr}}{Aug. 2021}
    %       \resumeItemListStart
    %         \resumeItem{Created a Shiny web app for users to input text and obtain multiple next word predictions}
    %         \resumeItem{Analyzed and cleaned over 4 million lines of text corpus data sourced from news, tweets, and blogs}
    %         \resumeItem{Utilized the Katz Back-Off (KBO) language model and Markov Chains to generate next word predictions}
    %       \resumeItemListEnd
    % \resumeSubHeadingListEnd


    